{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib        import pyplot\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"C:/temp/DSC_Project/Data/\"\n",
    "path = \"C:/Users/aahuile/Documents/GitHub/DSC_Project/\"\n",
    "#path = \"C:/Users/sbeyer/Documents/GitHub/DSC_Project/\"\n",
    "#path = \"C:/Users/sdam/Documents/GitHub/DSC_Project/\"\n",
    "#path = \"C:/Users/pborchert/Documents/GitHub/DSC_Project/\"\n",
    "#path = \"C:/Users/evrijghem/Documents/GitHub/DSC_Project/\"\n",
    "\n",
    "#Import CSV files\n",
    "gifts        = pd.read_csv(path + \"gifts.csv\", sep=\";\")\n",
    "donors       = pd.read_csv(path + \"donors.csv\", sep=\";\")\n",
    "camp13       = pd.read_csv(path + \"campaign20130411.csv\", sep=\";\")\n",
    "camp14       = pd.read_csv(path + \"campaign20140115.csv\", sep=\";\")\n",
    "region_codes = pd.read_csv(path + \"region_codes_belgium.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Gifts column\n",
    "gifts[\"date\"] = pd.to_datetime(gifts[\"date\"], format=\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier function definition\n",
    "outliers=[]\n",
    "def detect_outlier(data_1,col1):\n",
    "    \n",
    "    threshold=3\n",
    "    mean_1 = np.mean(data_1[col1])\n",
    "    std_1 =np.std(data_1[col1])\n",
    "    \n",
    "    \n",
    "    for y in data_1[col1]:\n",
    "        z_score= (y - mean_1)/std_1 \n",
    "        if np.abs(z_score) > threshold:\n",
    "            outliers.append(y)\n",
    "    return outliers\n",
    "\n",
    "#Select minimum outlier\n",
    "min_amt = min(detect_outlier(gifts,\"amount\"))\n",
    "#replace outliers bigger than the threshold value (minimum outlier) by the minimum outlier\n",
    "gifts.loc[gifts['amount']>min_amt,'amount']=min_amt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the region column, since we'll only be using provinces\n",
    "donors = donors.drop(columns=[\"region\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pandasql import sqldf\n",
    "\n",
    "#selecting the year from the gifts table needed for further analysis\n",
    "gifts['year'] = gifts['date'].dt.year\n",
    "\n",
    "#use sql to create a new test and training set from the gifts and donor table\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "dsc= pysqldf(\"\"\"\n",
    "SELECT c.*,d.gender,d.language,d.zipcode,\n",
    "        max(gf.amount) as max_gift, min(gf.amount) as min_gift,\n",
    "        avg(gf.amount) as mean_gift, min(gf.year) as first_gift,max(gf.year) as last_gift,\n",
    "        count(gf.year) as n_gifts, ((max(gf.date)-min(gf.date))*365)/count(gf.year) as avg_datediff,\n",
    "        max(case when gf.date<'2012-01-01' then 1 else 0 end) dormant_flag,\n",
    "        max(case when gf.campid=0 then 1 else 0 end) no_camp_flag\n",
    "FROM camp13 c\n",
    "    left join donors d on d.donorid=c.donorid \n",
    "    left join gifts gf on gf.donorid=c.donorid and gf.date<'2013-01-01'\n",
    "GROUP BY 1,2,3,4,5\n",
    "\"\"\")\n",
    "\n",
    "dsc_train= pysqldf(\"\"\"\n",
    "SELECT c.*,d.gender,d.language,d.zipcode,max(gf.amount) as max_gift, min(gf.amount) as min_gift,\n",
    "        avg(gf.amount) as mean_gift, min(gf.year) as first_gift,max(gf.year) as last_gift,\n",
    "        count(gf.year) as n_gifts, ((max(gf.date)-min(gf.date))*365)/count(gf.year) as avg_datediff,\n",
    "        max(case when gf.date<'2013-01-01' then 1 else 0 end) dormant_flag,\n",
    "        max(case when gf.campid=0 then 1 else 0 end) no_camp_flag\n",
    "FROM camp14 c\n",
    "    left join donors d on d.donorid=c.donorid \n",
    "    left join gifts gf on gf.donorid=c.donorid and gf.date<'2013-01-01'\n",
    "GROUP BY 1,2,3,4,5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Zip Codes\n",
    "#Region_codes table create start and end bracket\n",
    "region_codes[[\"Zip_start\", \"Zip_end\"]] = region_codes[\"Zipcode\"].str.split(\"?\", n = 2, expand = True)\n",
    "region_codes = region_codes.drop(columns=[\"Zipcode\"])\n",
    "region_codes.Zip_start = region_codes.Zip_start.astype(int)\n",
    "region_codes.Zip_end = region_codes.Zip_end.astype(int)\n",
    "\n",
    "# Convert Non numeric to NA values\n",
    "dsc[\"zipcode\"] = dsc[\"zipcode\"].str.replace('[^0-9]', \"0\")\n",
    "dsc_train[\"zipcode\"] = dsc_train[\"zipcode\"].str.replace('[^0-9]', \"0\")\n",
    "\n",
    "dsc.loc[dsc[\"zipcode\"].isna(),\"zipcode\"] = 0\n",
    "dsc_train.loc[dsc_train[\"zipcode\"].isna(),\"zipcode\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign Column Province in dsc\n",
    "#Create aux table\n",
    "aux = pysqldf(\"\"\"\n",
    "SELECT d.zipcode,r.province\n",
    "FROM dsc d\n",
    "JOIN region_codes r\n",
    "WHERE d.zipcode between r.zip_start and r.zip_end\n",
    "GROUP BY 1\n",
    "    UNION\n",
    "        SELECT d.zipcode,r.province\n",
    "        FROM dsc_train d\n",
    "        JOIN region_codes r\n",
    "        WHERE d.zipcode between r.zip_start and r.zip_end\n",
    "        GROUP BY 1\n",
    "\"\"\")\n",
    "#using pandas merge join the aux table with te dsc table\n",
    "dsc = pd.merge(dsc,aux,how='left',left_on='zipcode',right_on='zipcode')\n",
    "#replacing NA values with O\n",
    "dsc.loc[dsc[\"Province\"].isna(),\"Province\"] = \"0\"\n",
    "#Duplication of the previous commands for the train dataset\n",
    "dsc_train = pd.merge(dsc_train,aux,how='left',left_on='zipcode',right_on='zipcode')\n",
    "dsc_train.loc[dsc_train[\"Province\"].isna(),\"Province\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummies for the province variable in both tables\n",
    "prov_set = pd.get_dummies(dsc[\"Province\"])\n",
    "prov_t_set = pd.get_dummies(dsc_train[\"Province\"])\n",
    "\n",
    "#replace column 0 by prov_missing to indicate when the province was not specified\n",
    "prov_set.rename(columns={\"0\": \"Missing\"},inplace=True)\n",
    "prov_set = prov_set.add_prefix('prov_')\n",
    "prov_t_set.rename(columns={\"0\": \"Missing\"},inplace=True)\n",
    "prov_t_set = prov_t_set.add_prefix('prov_')\n",
    "\n",
    "#merge the province datatables with the dsc data tables\n",
    "dsc = pd.concat([dsc, prov_set], axis=1, join='inner')\n",
    "dsc_train = pd.concat([dsc_train, prov_set], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2154963680387407 %\n",
      "1.501090909090909 %\n",
      "8260\n"
     ]
    }
   ],
   "source": [
    "dsc_seg = pysqldf(\"\"\"\n",
    "select *, case when last_gift < 2011 and mean_gift > 20 and max_gift > 35 then \"inactive\" else \"active\" end as segment\n",
    "from dsc d\n",
    "\"\"\")\n",
    "ina = dsc_seg[dsc_seg[\"amount\"] >= 35].groupby(\"segment\").count()\n",
    "ones = ina.iloc[1,0]\n",
    "a = dsc_seg[dsc_seg[\"amount\"] < 35].groupby(\"segment\").count()\n",
    "zeros = a.iloc[1,0]\n",
    "print((ones/zeros)*100, \"%\")\n",
    "print((516 / 34375)*100, \"%\")\n",
    "print(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             donorID      amount    max_gift    min_gift   mean_gift  \\\n",
      "count     516.000000  516.000000  516.000000  516.000000  516.000000   \n",
      "mean   119917.951550   47.991996   36.821221   26.593760   31.185220   \n",
      "std     12570.073125   27.107563   23.000031   15.128755   16.827434   \n",
      "min    100126.000000   39.000000    5.000000    2.480000    5.000000   \n",
      "25%    109088.250000   40.000000   30.000000   24.790000   24.790000   \n",
      "50%    118665.000000   41.000000   32.250000   24.790000   30.000000   \n",
      "75%    130727.250000   50.000000   40.000000   30.000000   34.753250   \n",
      "max    144624.000000  476.870000  174.620000  174.620000  174.620000   \n",
      "\n",
      "        first_gift    last_gift     n_gifts  avg_datediff  dormant_flag  ...  \\\n",
      "count   516.000000   516.000000  516.000000    516.000000         516.0  ...   \n",
      "mean   2002.527132  2006.009690    4.482558    226.168605           1.0  ...   \n",
      "std       5.037070     4.389518    6.128850    298.064639           0.0  ...   \n",
      "min    1995.000000  1995.000000    1.000000      0.000000           1.0  ...   \n",
      "25%    1998.000000  2003.750000    1.000000      0.000000           1.0  ...   \n",
      "50%    2002.000000  2007.000000    2.000000    182.000000           1.0  ...   \n",
      "75%    2007.000000  2010.000000    5.000000    365.000000           1.0  ...   \n",
      "max    2010.000000  2012.000000   75.000000   2555.000000           1.0  ...   \n",
      "\n",
      "       prov_Brussels  prov_East Flanders  prov_Flemish Brabant  prov_Hainut  \\\n",
      "count     516.000000          516.000000            516.000000   516.000000   \n",
      "mean        0.017442            0.222868              0.176357     0.007752   \n",
      "std         0.131038            0.416574              0.381493     0.087788   \n",
      "min         0.000000            0.000000              0.000000     0.000000   \n",
      "25%         0.000000            0.000000              0.000000     0.000000   \n",
      "50%         0.000000            0.000000              0.000000     0.000000   \n",
      "75%         0.000000            0.000000              0.000000     0.000000   \n",
      "max         1.000000            1.000000              1.000000     1.000000   \n",
      "\n",
      "       prov_Liege  prov_Limburg  prov_Luxembourg  prov_Namur  \\\n",
      "count  516.000000    516.000000       516.000000  516.000000   \n",
      "mean     0.013566      0.085271         0.005814    0.005814   \n",
      "std      0.115792      0.279556         0.076101    0.076101   \n",
      "min      0.000000      0.000000         0.000000    0.000000   \n",
      "25%      0.000000      0.000000         0.000000    0.000000   \n",
      "50%      0.000000      0.000000         0.000000    0.000000   \n",
      "75%      0.000000      0.000000         0.000000    0.000000   \n",
      "max      1.000000      1.000000         1.000000    1.000000   \n",
      "\n",
      "       prov_Walloon Brabant  prov_West Flanders  \n",
      "count                 516.0          516.000000  \n",
      "mean                    0.0            0.220930  \n",
      "std                     0.0            0.415276  \n",
      "min                     0.0            0.000000  \n",
      "25%                     0.0            0.000000  \n",
      "50%                     0.0            0.000000  \n",
      "75%                     0.0            0.000000  \n",
      "max                     0.0            1.000000  \n",
      "\n",
      "[8 rows x 23 columns]\n",
      "             donorID        amount      max_gift      min_gift     mean_gift  \\\n",
      "count   34375.000000  34375.000000  34370.000000  34370.000000  34370.000000   \n",
      "mean   120997.533673      0.230361     30.767951     22.315184     25.810279   \n",
      "std     12214.365097      1.932551     24.990415     17.817974     19.045033   \n",
      "min    100001.000000      0.000000      5.000000      0.100000      0.621176   \n",
      "25%    110467.500000      0.000000     12.390000     10.000000     12.390000   \n",
      "50%    120762.000000      0.000000     30.000000     24.790000     24.790000   \n",
      "75%    131408.500000      0.000000     35.000000     30.000000     31.717738   \n",
      "max    144691.000000     30.000000    174.620000    174.620000    174.620000   \n",
      "\n",
      "         first_gift     last_gift       n_gifts  avg_datediff  dormant_flag  \\\n",
      "count  34370.000000  34370.000000  34375.000000  34370.000000  34375.000000   \n",
      "mean    2002.773378   2005.318243      4.254516    169.171021      0.999855   \n",
      "std        4.898848      4.329994      8.207611    264.747562      0.012060   \n",
      "min     1995.000000   1995.000000      0.000000      0.000000      0.000000   \n",
      "25%     1999.000000   2002.000000      1.000000      0.000000      1.000000   \n",
      "50%     2002.000000   2006.000000      2.000000      0.000000      1.000000   \n",
      "75%     2007.000000   2009.000000      4.000000    243.000000      1.000000   \n",
      "max     2010.000000   2012.000000    252.000000   2737.000000      1.000000   \n",
      "\n",
      "       ...  prov_Brussels  prov_East Flanders  prov_Flemish Brabant  \\\n",
      "count  ...   34375.000000        34375.000000          34375.000000   \n",
      "mean   ...       0.030458            0.209775              0.153455   \n",
      "std    ...       0.171847            0.407154              0.360430   \n",
      "min    ...       0.000000            0.000000              0.000000   \n",
      "25%    ...       0.000000            0.000000              0.000000   \n",
      "50%    ...       0.000000            0.000000              0.000000   \n",
      "75%    ...       0.000000            0.000000              0.000000   \n",
      "max    ...       1.000000            1.000000              1.000000   \n",
      "\n",
      "        prov_Hainut    prov_Liege  prov_Limburg  prov_Luxembourg  \\\n",
      "count  34375.000000  34375.000000  34375.000000     34375.000000   \n",
      "mean       0.016000      0.016349      0.111825         0.005178   \n",
      "std        0.125477      0.126816      0.315156         0.071774   \n",
      "min        0.000000      0.000000      0.000000         0.000000   \n",
      "25%        0.000000      0.000000      0.000000         0.000000   \n",
      "50%        0.000000      0.000000      0.000000         0.000000   \n",
      "75%        0.000000      0.000000      0.000000         0.000000   \n",
      "max        1.000000      1.000000      1.000000         1.000000   \n",
      "\n",
      "         prov_Namur  prov_Walloon Brabant  prov_West Flanders  \n",
      "count  34375.000000          34375.000000        34375.000000  \n",
      "mean       0.006575              0.008058            0.203084  \n",
      "std        0.080818              0.089406            0.402300  \n",
      "min        0.000000              0.000000            0.000000  \n",
      "25%        0.000000              0.000000            0.000000  \n",
      "50%        0.000000              0.000000            0.000000  \n",
      "75%        0.000000              0.000000            0.000000  \n",
      "max        1.000000              1.000000            1.000000  \n",
      "\n",
      "[8 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "gg = dsc_seg[dsc_seg[\"amount\"] >= 35]\n",
    "print(gg.describe())\n",
    "gg2 = dsc_seg[dsc_seg[\"amount\"] < 35]\n",
    "print(gg2.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean DSC last_gift, first_gift column (replace NA with mean)\n",
    "dsc.loc[dsc[\"last_gift\"].isna(),\"last_gift\"] = dsc.loc[dsc[\"last_gift\"].notna(),\"last_gift\"].mean()\n",
    "dsc[\"last_gift\"] = dsc[\"last_gift\"].astype(int)\n",
    "dsc[\"last_gift\"] = 2013 - dsc[\"last_gift\"]\n",
    "\n",
    "dsc.loc[dsc[\"first_gift\"].isna(),\"first_gift\"] = dsc.loc[dsc[\"first_gift\"].notna(),\"first_gift\"].mean()\n",
    "dsc[\"first_gift\"] = dsc[\"first_gift\"].astype(int)\n",
    "dsc[\"first_gift\"] = 2013 - dsc[\"first_gift\"]\n",
    "\n",
    "#Clean DSC n_gifts column (Type to int)\n",
    "dsc.n_gifts = dsc.n_gifts.astype(int)\n",
    "\n",
    "#same for the dsc_train dataset\n",
    "dsc_train.loc[dsc_train[\"last_gift\"].isna(),\"last_gift\"] = dsc_train.loc[dsc_train[\"last_gift\"].notna(),\"last_gift\"].mean()\n",
    "dsc_train[\"last_gift\"] = dsc_train[\"last_gift\"].astype(int)\n",
    "dsc_train[\"last_gift\"] = 2014 - dsc_train[\"last_gift\"]\n",
    "\n",
    "dsc_train.loc[dsc_train[\"first_gift\"].isna(),\"first_gift\"] = dsc_train.loc[dsc_train[\"first_gift\"].notna(),\"first_gift\"].mean()\n",
    "dsc_train[\"first_gift\"] = dsc_train[\"first_gift\"].astype(int)\n",
    "dsc_train[\"first_gift\"] = 2014 - dsc_train[\"first_gift\"]\n",
    "\n",
    "dsc_train.n_gifts = dsc_train.n_gifts.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean DSC max_gift, min_gift, mean_gift (replace NA with mean)\n",
    "dsc.loc[dsc[\"max_gift\"].isna(),\"max_gift\"] = dsc.loc[dsc[\"max_gift\"].notna(),\"max_gift\"].mean()\n",
    "dsc[\"max_gift\"] = dsc[\"max_gift\"].astype(float)\n",
    "\n",
    "dsc.loc[dsc[\"min_gift\"].isna(),\"min_gift\"] = dsc.loc[dsc[\"min_gift\"].notna(),\"min_gift\"].mean()\n",
    "dsc[\"min_gift\"] = dsc[\"min_gift\"].astype(float)\n",
    "\n",
    "dsc.loc[dsc[\"mean_gift\"].isna(),\"mean_gift\"] = dsc.loc[dsc[\"mean_gift\"].notna(),\"mean_gift\"].mean()\n",
    "dsc[\"mean_gift\"] = dsc[\"mean_gift\"].astype(float)\n",
    "\n",
    "#same for the dsc_train dataset\n",
    "dsc_train.loc[dsc_train[\"max_gift\"].isna(),\"max_gift\"] = dsc_train.loc[dsc_train[\"max_gift\"].notna(),\"max_gift\"].mean()\n",
    "dsc_train[\"max_gift\"] = dsc_train[\"max_gift\"].astype(float)\n",
    "\n",
    "dsc_train.loc[dsc_train[\"min_gift\"].isna(),\"min_gift\"] = dsc_train.loc[dsc_train[\"min_gift\"].notna(),\"min_gift\"].mean()\n",
    "dsc_train[\"min_gift\"] = dsc_train[\"min_gift\"].astype(float)\n",
    "\n",
    "dsc_train.loc[dsc_train[\"mean_gift\"].isna(),\"mean_gift\"] = dsc_train.loc[dsc_train[\"mean_gift\"].notna(),\"mean_gift\"].mean()\n",
    "dsc_train[\"mean_gift\"] = dsc_train[\"mean_gift\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace NA values with 0 for both datasets\n",
    "dsc.loc[dsc[\"avg_datediff\"].isna(),\"avg_datediff\"] = 0\n",
    "dsc_train.loc[dsc_train[\"avg_datediff\"].isna(),\"avg_datediff\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename gender types for both datasets\n",
    "dictionary = {\"M\": \"Male\", \"F\": \"Female\", \"C\": \"Couple\", \"S\": \"SoHo\", \"U\": \"Unknown\"}\n",
    "dsc = dsc.replace({\"gender\": dictionary})\n",
    "dsc_train = dsc_train.replace({\"gender\": dictionary})\n",
    "\n",
    "#Create dummies for the gender variable, add \"gender_\"\n",
    "gend_set = pd.get_dummies(dsc[\"gender\"])\n",
    "gend_set = gend_set.add_prefix('gender_')\n",
    "gend_t_set = pd.get_dummies(dsc_train[\"gender\"])\n",
    "gend_t_set = gend_t_set.add_prefix('gender_')\n",
    "\n",
    "#add gender to both datasets \n",
    "dsc = pd.concat([dsc, gend_set], axis=1, join='inner')\n",
    "dsc_train = pd.concat([dsc_train, gend_t_set], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummies for the language variable\n",
    "dictionary = {\"N\": 1, \"F\": 0}\n",
    "dsc = dsc.replace({\"language\": dictionary})\n",
    "dsc_train = dsc_train.replace({\"language\": dictionary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary y-variable for models which reflects the threshold value of a gift of 35\n",
    "dsc['y'] = (dsc[\"amount\"] >= 35) * 1\n",
    "dsc_train['y'] = (dsc_train[\"amount\"] >= 35) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc_copy = dsc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping redundant or non_usable columns\n",
    "dsc.drop(columns=['Province','zipcode','prov_Missing','gender_Unknown','gender','donorID'],axis=1,inplace=True)\n",
    "dsc_train.drop(columns=['Province','zipcode','prov_Missing','gender_Unknown','gender','donorID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting train set for validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dsc_train[dsc_train.columns[~dsc_train.columns.isin(['y','mean_gift'])]]\n",
    "y = dsc_train[['y']]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# X2 = X.loc[:,['max_gift', 'min_gift', 'first_gift','mean_gift',\n",
    "#       'last_gift', 'n_gifts', 'avg_datediff']].values\n",
    "# scaler = StandardScaler()\n",
    "# X3 = scaler.fit_transform(X2)\n",
    "# X[['max_gift', 'min_gift', 'first_gift','mean_gift',\n",
    "#        'last_gift', 'n_gifts', 'avg_datediff']] = X3\n",
    "# X.head()\n",
    "\n",
    "# from sklearn.preprocessing import scale\n",
    "# X2 = X.loc[:,['max_gift', 'min_gift', 'first_gift','mean_gift',\n",
    "#       'last_gift', 'n_gifts', 'avg_datediff']].values\n",
    "# X3 = scale(X2)\n",
    "# X[['max_gift', 'min_gift', 'first_gift','mean_gift',\n",
    "#        'last_gift', 'n_gifts', 'avg_datediff']] = X3\n",
    "# X.head()\n",
    "\n",
    "X2 = np.log(X.loc[:,['max_gift', 'min_gift', 'first_gift','mean_gift',\n",
    "      'last_gift', 'n_gifts', 'avg_datediff']]+1)\n",
    "X[['max_gift', 'min_gift', 'first_gift','mean_gift',\n",
    "       'last_gift', 'n_gifts', 'avg_datediff']] = X2\n",
    "\n",
    "# X2 = normalize(np.log(X.loc[:,['max_gift', 'min_gift', 'first_gift','mean_gift',\n",
    "#       'last_gift', 'n_gifts', 'avg_datediff']]+1))\n",
    "# X[['max_gift', 'min_gift', 'first_gift','mean_gift',\n",
    "#        'last_gift', 'n_gifts', 'avg_datediff']] = X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e58b81ad30>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAASC0lEQVR4nO3cf6zd9V3H8efLdkxkLsBwN9g2liXNHI6M4Q1UMea6GShoLCZbAiGj2TBdDMTNNNFu/sEcLnGJbAqZxG7UFYMwZNM2oxs2lZvFZDDKRiisw15ZHRcqdZYxuiXO6ts/zufOk3Ju7+257f3x7fORnJzzfZ/P93s+737JffH93O89qSokSae3n1joCUiSFp5hIEkyDCRJhoEkCcNAkgQsX+gJDOu8886r1atXD7XvD37wA84666yTO6EF1sWeoJt9dbEn6GZfXezp8ccf/25V/cyx9SUbBqtXr2bPnj1D7Ts+Ps7Y2NjJndAC62JP0M2+utgTdLOvLvaU5N8G1V0mkiQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiRmEQZJViV5OMm+JE8n+UCrfyTJ80meaI+r+/b5UJKJJM8kubKvvq7VJpJs7qtfkOTRJPuTfC7JGSe7UUnS9GZzZXAU2FRVbwHWAjclubC998mqurg9dgK0964FfgFYB/xlkmVJlgGfAq4CLgSu6zvOx9ux1gAvATeepP4G2vv8y6ze/CCrNz94Kj9GkpaMGcOgqg5W1dfb61eAfcCK4+yyHrivqv6rqr4NTACXtsdEVT1bVT8C7gPWJwnwDuCBtv824JphG5IknbgT+m6iJKuBtwOPApcDNye5AdhD7+rhJXpB8UjfbpP8f3g8d0z9MuANwPeq6uiA8cd+/kZgI8DIyAjj4+MnMv0fGzkTNl3U+7hhj7HYHDlypDO99OtiX13sCbrZVxd7ms6swyDJ64DPAx+squ8nuRO4Faj2fBvwPiADdi8GX4XUcca/uli1BdgCMDo6WsN+gdQd92zntr291g9cP9wxFpsufqEWdLOvLvYE3eyriz1NZ1ZhkOQ19ILgnqr6AkBVvdj3/qeBL7bNSWBV3+4rgRfa60H17wJnJ1nerg76x0uS5sFs7iYKcBewr6o+0Vc/v2/YbwNPtdc7gGuTvDbJBcAa4GvAY8CadufQGfR+ybyjqgp4GHhX238DsH1ubUmSTsRsrgwuB94D7E3yRKt9mN7dQBfTW9I5ALwfoKqeTnI/8E16dyLdVFX/A5DkZuAhYBmwtaqebsf7Q+C+JH8CfINe+EiS5smMYVBV/8zgdf2dx9nnY8DHBtR3Dtqvqp6ld7eRJGkB+BfIkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAksQswiDJqiQPJ9mX5OkkH2j1c5PsSrK/PZ/T6klye5KJJE8muaTvWBva+P1JNvTVfzHJ3rbP7UlyKpqVJA02myuDo8CmqnoLsBa4KcmFwGZgd1WtAXa3bYCrgDXtsRG4E3rhAdwCXAZcCtwyFSBtzMa+/dbNvTVJ0mzNGAZVdbCqvt5evwLsA1YA64Ftbdg24Jr2ej1wd/U8Apyd5HzgSmBXVR2uqpeAXcC69t7rq+qrVVXA3X3HkiTNg+UnMjjJauDtwKPASFUdhF5gJHljG7YCeK5vt8lWO159ckB90OdvpHcFwcjICOPj4ycy/R8bORM2XXQUYOhjLDZHjhzpTC/9uthXF3uCbvbVxZ6mM+swSPI64PPAB6vq+8dZ1h/0Rg1Rf3WxaguwBWB0dLTGxsZmmPVgd9yzndv29lo/cP1wx1hsxsfHGfbfYzHrYl9d7Am62VcXe5rOrO4mSvIaekFwT1V9oZVfbEs8tOdDrT4JrOrbfSXwwgz1lQPqkqR5Mpu7iQLcBeyrqk/0vbUDmLojaAOwva9+Q7uraC3wcltOegi4Isk57RfHVwAPtfdeSbK2fdYNfceSJM2D2SwTXQ68B9ib5IlW+zDwp8D9SW4EvgO8u723E7gamAB+CLwXoKoOJ7kVeKyN+2hVHW6vfxf4LHAm8KX2kCTNkxnDoKr+mcHr+gDvHDC+gJumOdZWYOuA+h7grTPNRZJ0avgXyJIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJLELMIgydYkh5I81Vf7SJLnkzzRHlf3vfehJBNJnklyZV99XatNJNncV78gyaNJ9if5XJIzTmaDkqSZzebK4LPAugH1T1bVxe2xEyDJhcC1wC+0ff4yybIky4BPAVcBFwLXtbEAH2/HWgO8BNw4l4YkSSduxjCoqq8Ah2d5vPXAfVX1X1X1bWACuLQ9Jqrq2ar6EXAfsD5JgHcAD7T9twHXnGAPkqQ5Wj6HfW9OcgOwB9hUVS8BK4BH+sZMthrAc8fULwPeAHyvqo4OGP8qSTYCGwFGRkYYHx8fauIjZ8Kmi3ofOewxFpsjR450ppd+Xeyriz1BN/vqYk/TGTYM7gRuBao93wa8D8iAscXgK5A6zviBqmoLsAVgdHS0xsbGTmjSU+64Zzu37e21fuD64Y6x2IyPjzPsv8di1sW+utgTdLOvLvY0naHCoKpenHqd5NPAF9vmJLCqb+hK4IX2elD9u8DZSZa3q4P+8ZKkeTLUraVJzu/b/G1g6k6jHcC1SV6b5AJgDfA14DFgTbtz6Ax6v2TeUVUFPAy8q+2/Adg+zJwkScOb8cogyb3AGHBekkngFmAsycX0lnQOAO8HqKqnk9wPfBM4CtxUVf/TjnMz8BCwDNhaVU+3j/hD4L4kfwJ8A7jrpHUnSZqVGcOgqq4bUJ72B3ZVfQz42ID6TmDngPqz9O42kiQtEP8CWZJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJKYRRgk2ZrkUJKn+mrnJtmVZH97PqfVk+T2JBNJnkxySd8+G9r4/Uk29NV/Mcnets/tSXKym5QkHd9srgw+C6w7prYZ2F1Va4DdbRvgKmBNe2wE7oReeAC3AJcBlwK3TAVIG7Oxb79jP0uSdIrNGAZV9RXg8DHl9cC29nobcE1f/e7qeQQ4O8n5wJXArqo6XFUvAbuAde2911fVV6uqgLv7jiVJmifLh9xvpKoOAlTVwSRvbPUVwHN94yZb7Xj1yQH1gZJspHcVwcjICOPj48NN/kzYdNFRgKGPsdgcOXKkM73062JfXewJutlXF3uazrBhMJ1B6/01RH2gqtoCbAEYHR2tsbGxIaYId9yzndv29lo/cP1wx1hsxsfHGfbfYzHrYl9d7Am62VcXe5rOsHcTvdiWeGjPh1p9EljVN24l8MIM9ZUD6pKkeTRsGOwApu4I2gBs76vf0O4qWgu83JaTHgKuSHJO+8XxFcBD7b1XkqxtdxHd0HcsSdI8mXGZKMm9wBhwXpJJencF/Slwf5Ibge8A727DdwJXAxPAD4H3AlTV4SS3Ao+1cR+tqqlfSv8uvTuWzgS+1B6SpHk0YxhU1XXTvPXOAWMLuGma42wFtg6o7wHeOtM8JEmnjn+BLEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEnMMQySHEiyN8kTSfa02rlJdiXZ357PafUkuT3JRJInk1zSd5wNbfz+JBvm1pIk6USdjCuDX6uqi6tqtG1vBnZX1Rpgd9sGuApY0x4bgTuhFx7ALcBlwKXALVMBIkmaH6dimWg9sK293gZc01e/u3oeAc5Ocj5wJbCrqg5X1UvALmDdKZiXJGkay+e4fwH/mKSAv6qqLcBIVR0EqKqDSd7Yxq4Anuvbd7LVpqu/SpKN9K4qGBkZYXx8fKhJj5wJmy46CjD0MRabI0eOdKaXfl3sq4s9QTf76mJP05lrGFxeVS+0H/i7knzrOGMzoFbHqb+62AubLQCjo6M1NjZ2gtPtueOe7dy2t9f6geuHO8ZiMz4+zrD/HotZF/vqYk/Qzb662NN05rRMVFUvtOdDwN/TW/N/sS3/0J4PteGTwKq+3VcCLxynLkmaJ0OHQZKzkvz01GvgCuApYAcwdUfQBmB7e70DuKHdVbQWeLktJz0EXJHknPaL4ytaTZI0T+ayTDQC/H2SqeP8bVV9OcljwP1JbgS+A7y7jd8JXA1MAD8E3gtQVYeT3Ao81sZ9tKoOz2FekqQTNHQYVNWzwNsG1P8TeOeAegE3TXOsrcDWYeciSZob/wJZkmQYSJIMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIklhEYZBkXZJnkkwk2bzQ85Gk08miCIMky4BPAVcBFwLXJblwYWclSaePRREGwKXARFU9W1U/Au4D1i/wnIa2evODP35oeKs3P8je51/231GaB6mqhZ4DSd4FrKuq32nb7wEuq6qbjxm3EdjYNt8MPDPkR54HfHfIfRerLvYE3eyriz1BN/vqYk8/V1U/c2xx+ULMZIAMqL0qpapqC7Blzh+W7Kmq0bkeZzHpYk/Qzb662BN0s68u9jSdxbJMNAms6tteCbywQHORpNPOYgmDx4A1SS5IcgZwLbBjgeckSaeNRbFMVFVHk9wMPAQsA7ZW1dOn8CPnvNS0CHWxJ+hmX13sCbrZVxd7GmhR/AJZkrSwFssykSRpARkGkqTTKwy68pUXSVYleTjJviRPJ/lAq5+bZFeS/e35nIWe64lKsizJN5J8sW1fkOTR1tPn2g0GS0qSs5M8kORb7Zz90lI/V0l+v/2391SSe5P85FI8V0m2JjmU5Km+2sBzk57b28+PJ5NcsnAzP/lOmzDo2FdeHAU2VdVbgLXATa2XzcDuqloD7G7bS80HgH192x8HPtl6egm4cUFmNTd/AXy5qn4eeBu9/pbsuUqyAvg9YLSq3krvpo9rWZrn6rPAumNq052bq4A17bERuHOe5jgvTpswoENfeVFVB6vq6+31K/R+uKyg18+2NmwbcM3CzHA4SVYCvwF8pm0HeAfwQBuyFHt6PfCrwF0AVfWjqvoeS/xc0bsT8cwky4GfAg6yBM9VVX0FOHxMebpzsx64u3oeAc5Ocv78zPTUO53CYAXwXN/2ZKstaUlWA28HHgVGquog9AIDeOPCzWwofw78AfC/bfsNwPeq6mjbXorn7E3AfwB/3Za/PpPkLJbwuaqq54E/A75DLwReBh5n6Z+rKdOdm07+DJlyOoXBrL7yYilJ8jrg88AHq+r7Cz2fuUjym8Chqnq8vzxg6FI7Z8uBS4A7q+rtwA9YQktCg7Q19PXABcDPAmfRW0I51lI7VzPpwn+P0zqdwqBTX3mR5DX0guCeqvpCK784ddnang8t1PyGcDnwW0kO0FvCewe9K4Wz21IELM1zNglMVtWjbfsBeuGwlM/VrwPfrqr/qKr/Br4A/DJL/1xNme7cdOpnyLFOpzDozFdetLX0u4B9VfWJvrd2ABva6w3A9vme27Cq6kNVtbKqVtM7N/9UVdcDDwPvasOWVE8AVfXvwHNJ3txK7wS+yRI+V/SWh9Ym+an23+JUT0v6XPWZ7tzsAG5odxWtBV6eWk7qhKo6bR7A1cC/AP8K/NFCz2cOffwKvcvTJ4En2uNqemvsu4H97fnchZ7rkP2NAV9sr98EfA2YAP4OeO1Cz2+Ifi4G9rTz9Q/AOUv9XAF/DHwLeAr4G+C1S/FcAffS+73Hf9P7P/8bpzs39JaJPtV+fuyldzfVgvdwsh5+HYUk6bRaJpIkTcMwkCQZBpIkw0CShGEgScIwkCRhGEiSgP8DsnziOU0iyskAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dsc_train['amount'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsampling observations with amount > 35 in training Set\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = dsc_train[dsc_train.y==0]\n",
    "df_minority = dsc_train[dsc_train.y==1]\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=51,    # to match majority class\n",
    "                                 random_state=123)\n",
    "df_upsampled = pd.concat([dsc_train, df_minority_upsampled])\n",
    "\n",
    "y = df_upsampled.y\n",
    "X = df_upsampled.drop('y', axis=1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e58b658828>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAASJElEQVR4nO3cf6zddX3H8edrrTiGM4DMG9Y2KyaNk0lEdgPdWJY7XaDgsrJEEwiRTllqDGS6NNnq9gdONNFk6AZRsiqdZWEiQ10b6caajhuzZCBFCQWr6x12cqWjc0Wkmqh17/1xPtedlHN7b89t749vn4/k5Hy/7/P5fs/nfb/NffX7Pd97UlVIkk5vP7PQE5AkLTzDQJJkGEiSDANJEoaBJAlYvtATGNZ5551Xq1evHmrb73//+5x11lknd0ILrIs9QTf76mJP0M2+utjTY4899p2q+oVj60s2DFavXs2ePXuG2nZ8fJyxsbGTO6EF1sWeoJt9dbEn6GZfXewpyX8OqnuZSJJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJKYRRgkWZXkoST7kjyV5D2t/v4k307yeHtc3bfN+5JMJPlGkiv76utabSLJ5r76BUkeSbI/yWeTnHGyG5UkTW82ZwZHgU1V9TpgLXBTkgvbax+rqovbYydAe+1a4FeAdcAnkixLsgz4OHAVcCFwXd9+PtL2tQZ4HrjxJPU30N5vv8DqzQ+wevMDp/JtJGnJmDEMqupgVX2lLb8I7ANWHGeT9cC9VfXDqvomMAFc2h4TVfV0Vf0IuBdYnyTAm4D72/bbgGuGbUiSdOJO6LuJkqwG3gg8AlwO3JzkBmAPvbOH5+kFxcN9m03y/+HxzDH1y4BXAd+tqqMDxh/7/huBjQAjIyOMj4+fyPR/auRM2HRR7+2G3cdic+TIkc700q+LfXWxJ+hmX13saTqzDoMkrwA+B7y3qr6X5E7gVqDa823AO4EM2LwYfBZSxxn/0mLVFmALwOjoaA37BVJ33LOd2/b2Wj9w/XD7WGy6+IVa0M2+utgTdLOvLvY0nVmFQZKX0QuCe6rq8wBV9Vzf658EvthWJ4FVfZuvBJ5ty4Pq3wHOTrK8nR30j5ckzYPZ3E0U4C5gX1V9tK9+ft+w3wOebMs7gGuTvDzJBcAa4MvAo8CadufQGfQ+ZN5RVQU8BLy1bb8B2D63tiRJJ2I2ZwaXA28H9iZ5vNX+lN7dQBfTu6RzAHgXQFU9leQ+4Gv07kS6qap+ApDkZuBBYBmwtaqeavv7E+DeJB8EvkovfCRJ82TGMKiqf2Xwdf2dx9nmQ8CHBtR3Dtquqp6md7eRJGkB+BfIkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAksQswiDJqiQPJdmX5Kkk72n1c5PsSrK/PZ/T6klye5KJJE8kuaRvXxva+P1JNvTVfzXJ3rbN7UlyKpqVJA02mzODo8CmqnodsBa4KcmFwGZgd1WtAXa3dYCrgDXtsRG4E3rhAdwCXAZcCtwyFSBtzMa+7dbNvTVJ0mzNGAZVdbCqvtKWXwT2ASuA9cC2NmwbcE1bXg/cXT0PA2cnOR+4EthVVYer6nlgF7CuvfbKqvq3qirg7r59SZLmwfITGZxkNfBG4BFgpKoOQi8wkry6DVsBPNO32WSrHa8+OaA+6P030juDYGRkhPHx8ROZ/k+NnAmbLjoKMPQ+FpsjR450ppd+Xeyriz1BN/vqYk/TmXUYJHkF8DngvVX1veNc1h/0Qg1Rf2mxaguwBWB0dLTGxsZmmPVgd9yzndv29lo/cP1w+1hsxsfHGfbnsZh1sa8u9gTd7KuLPU1nVncTJXkZvSC4p6o+38rPtUs8tOdDrT4JrOrbfCXw7Az1lQPqkqR5Mpu7iQLcBeyrqo/2vbQDmLojaAOwva9+Q7uraC3wQruc9CBwRZJz2gfHVwAPttdeTLK2vdcNffuSJM2D2Vwmuhx4O7A3yeOt9qfAh4H7ktwIfAt4W3ttJ3A1MAH8AHgHQFUdTnIr8Ggb94GqOtyW3w18GjgT+Mf2kCTNkxnDoKr+lcHX9QHePGB8ATdNs6+twNYB9T3A62eaiyTp1PAvkCVJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJWYRBkq1JDiV5sq/2/iTfTvJ4e1zd99r7kkwk+UaSK/vq61ptIsnmvvoFSR5Jsj/JZ5OccTIblCTNbDZnBp8G1g2of6yqLm6PnQBJLgSuBX6lbfOJJMuSLAM+DlwFXAhc18YCfKTtaw3wPHDjXBqSJJ24GcOgqr4EHJ7l/tYD91bVD6vqm8AEcGl7TFTV01X1I+BeYH2SAG8C7m/bbwOuOcEeJElztHwO296c5AZgD7Cpqp4HVgAP942ZbDWAZ46pXwa8CvhuVR0dMP4lkmwENgKMjIwwPj4+1MRHzoRNF/Xecth9LDZHjhzpTC/9uthXF3uCbvbVxZ6mM2wY3AncClR7vg14J5ABY4vBZyB1nPEDVdUWYAvA6OhojY2NndCkp9xxz3Zu29tr/cD1w+1jsRkfH2fYn8di1sW+utgTdLOvLvY0naHCoKqem1pO8kngi211EljVN3Ql8GxbHlT/DnB2kuXt7KB/vCRpngx1a2mS8/tWfw+YutNoB3BtkpcnuQBYA3wZeBRY0+4cOoPeh8w7qqqAh4C3tu03ANuHmZMkaXgznhkk+QwwBpyXZBK4BRhLcjG9SzoHgHcBVNVTSe4DvgYcBW6qqp+0/dwMPAgsA7ZW1VPtLf4EuDfJB4GvAnedtO4kSbMyYxhU1XUDytP+wq6qDwEfGlDfCewcUH+a3t1GkqQF4l8gS5IMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKzCIMkW5McSvJkX+3cJLuS7G/P57R6ktyeZCLJE0ku6dtmQxu/P8mGvvqvJtnbtrk9SU52k5Kk45vNmcGngXXH1DYDu6tqDbC7rQNcBaxpj43AndALD+AW4DLgUuCWqQBpYzb2bXfse0mSTrEZw6CqvgQcPqa8HtjWlrcB1/TV766eh4Gzk5wPXAnsqqrDVfU8sAtY1157ZVX9W1UVcHffviRJ82T5kNuNVNVBgKo6mOTVrb4CeKZv3GSrHa8+OaA+UJKN9M4iGBkZYXx8fLjJnwmbLjoKMPQ+FpsjR450ppd+Xeyriz1BN/vqYk/TGTYMpjPoen8NUR+oqrYAWwBGR0drbGxsiCnCHfds57a9vdYPXD/cPhab8fFxhv15LGZd7KuLPUE3++piT9MZ9m6i59olHtrzoVafBFb1jVsJPDtDfeWAuiRpHg0bBjuAqTuCNgDb++o3tLuK1gIvtMtJDwJXJDmnfXB8BfBge+3FJGvbXUQ39O1LkjRPZrxMlOQzwBhwXpJJencFfRi4L8mNwLeAt7XhO4GrgQngB8A7AKrqcJJbgUfbuA9U1dSH0u+md8fSmcA/tockaR7NGAZVdd00L715wNgCbppmP1uBrQPqe4DXzzQPSdKp418gS5IMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRJzDIMkB5LsTfJ4kj2tdm6SXUn2t+dzWj1Jbk8ykeSJJJf07WdDG78/yYa5tSRJOlEn48zgt6rq4qoabeubgd1VtQbY3dYBrgLWtMdG4E7ohQdwC3AZcClwy1SASJLmx6m4TLQe2NaWtwHX9NXvrp6HgbOTnA9cCeyqqsNV9TywC1h3CuYlSZrG8jluX8A/Jyngr6tqCzBSVQcBqupgkle3sSuAZ/q2nWy16eovkWQjvbMKRkZGGB8fH2rSI2fCpouOAgy9j8XmyJEjnemlXxf76mJP0M2+utjTdOYaBpdX1bPtF/6uJF8/ztgMqNVx6i8t9sJmC8Do6GiNjY2d4HR77rhnO7ft7bV+4Prh9rHYjI+PM+zPYzHrYl9d7Am62VcXe5rOnC4TVdWz7fkQ8AV61/yfa5d/aM+H2vBJYFXf5iuBZ49TlyTNk6HDIMlZSX5+ahm4AngS2AFM3RG0AdjelncAN7S7itYCL7TLSQ8CVyQ5p31wfEWrSZLmyVwuE40AX0gytZ+/q6p/SvIocF+SG4FvAW9r43cCVwMTwA+AdwBU1eEktwKPtnEfqKrDc5iXJOkEDR0GVfU08IYB9f8B3jygXsBN0+xrK7B12LlIkubGv0CWJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJBZRGCRZl+QbSSaSbF7o+UjS6WRRhEGSZcDHgauAC4Hrkly4sLOSpNPH8oWeQHMpMFFVTwMkuRdYD3xtQWc1pNWbH/jp8oEPv2UBZ7K0rd78AJsuOsrvb37glP0cPVZST6pqoedAkrcC66rqD9r624HLqurmY8ZtBDa21dcC3xjyLc8DvjPktotVF3uCbvbVxZ6gm311sadfqqpfOLa4WM4MMqD2kpSqqi3Aljm/WbKnqkbnup/FpIs9QTf76mJP0M2+utjTdBbFZwbAJLCqb30l8OwCzUWSTjuLJQweBdYkuSDJGcC1wI4FnpMknTYWxWWiqjqa5GbgQWAZsLWqnjqFbznnS02LUBd7gm721cWeoJt9dbGngRbFB8iSpIW1WC4TSZIWkGEgSTq9wqArX3mRZFWSh5LsS/JUkve0+rlJdiXZ357PWei5nqgky5J8NckX2/oFSR5pPX223WCwpCQ5O8n9Sb7ejtmvLfVjleSP2r+9J5N8JsnPLsVjlWRrkkNJnuyrDTw26bm9/f54IsklCzfzk++0CYOOfeXFUWBTVb0OWAvc1HrZDOyuqjXA7ra+1LwH2Ne3/hHgY62n54EbF2RWc/NXwD9V1S8Db6DX35I9VklWAH8IjFbV6+nd9HEtS/NYfRpYd0xtumNzFbCmPTYCd87THOfFaRMG9H3lRVX9CJj6yoslp6oOVtVX2vKL9H65rKDXz7Y2bBtwzcLMcDhJVgJvAT7V1gO8Cbi/DVmKPb0S+E3gLoCq+lFVfZclfqzo3Yl4ZpLlwM8BB1mCx6qqvgQcPqY83bFZD9xdPQ8DZyc5f35meuqdTmGwAnimb32y1Za0JKuBNwKPACNVdRB6gQG8euFmNpS/BP4Y+N+2/irgu1V1tK0vxWP2GuC/gb9pl78+leQslvCxqqpvA38BfIteCLwAPMbSP1ZTpjs2nfwdMuV0CoNZfeXFUpLkFcDngPdW1fcWej5zkeR3gENV9Vh/ecDQpXbMlgOXAHdW1RuB77OELgkN0q6hrwcuAH4ROIveJZRjLbVjNZMu/Huc1ukUBp36yoskL6MXBPdU1edb+bmp09b2fGih5jeEy4HfTXKA3iW8N9E7Uzi7XYqApXnMJoHJqnqkrd9PLxyW8rH6beCbVfXfVfVj4PPAr7P0j9WU6Y5Np36HHOt0CoPOfOVFu5Z+F7Cvqj7a99IOYENb3gBsn++5Dauq3ldVK6tqNb1j8y9VdT3wEPDWNmxJ9QRQVf8FPJPkta30Znpfzb5kjxW9y0Nrk/xc+7c41dOSPlZ9pjs2O4Ab2l1Fa4EXpi4ndUJVnTYP4Grg34H/AP5soeczhz5+g97p6RPA4+1xNb1r7LuB/e353IWe65D9jQFfbMuvAb4MTAB/D7x8oec3RD8XA3va8foH4JylfqyAPwe+DjwJ/C3w8qV4rIDP0Pvc48f0/ud/43THht5loo+33x976d1NteA9nKyHX0chSTqtLhNJkqZhGEiSDANJkmEgScIwkCRhGEiSMAwkScD/Afbo4hy+EN8QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_upsampled[\"amount\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.linear_model    import LinearRegression\n",
    "from sklearn.linear_model    import Ridge\n",
    "from sklearn.linear_model    import Lasso\n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.ensemble        import GradientBoostingClassifier\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.neural_network  import MLPClassifier\n",
    "from sklearn.neural_network  import MLPRegressor\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.metrics         import auc\n",
    "from sklearn.metrics         import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgboost\n",
    "\n",
    "trainingSet = pd.concat([X_train,y_train],axis=1,join='inner').reset_index(drop=True)\n",
    "testSet     = dsc\n",
    "validationSet = pd.concat([X_valid,y_valid],axis=1,join='inner').reset_index(drop=True)\n",
    "\n",
    "nofeature = [\"y\", \"mean_gift\",\"amount\"]\n",
    "features = list(set(dsc.columns).difference(set(nofeature)))\n",
    "target= 'y'\n",
    "\n",
    "tree         = DecisionTreeClassifier(class_weight = \"balanced\", max_depth=6)\n",
    "logistic     = LogisticRegression(solver = \"lbfgs\", class_weight = \"balanced\", max_iter= 200) # max_iter = 5000, penalty=\"l2\",lbfgs \n",
    "linear       = LinearRegression()\n",
    "ridge        = Ridge(alpha = 0.5, normalize=True)\n",
    "lasso        = Lasso(alpha = 0.5, normalize=False)\n",
    "randomForest = RandomForestClassifier(class_weight = \"balanced\", n_estimators = 100, max_depth=10)\n",
    "boostedTree  = GradientBoostingClassifier(max_depth=10)\n",
    "svm          = SVC(probability = True, class_weight='balanced', kernel='linear')\n",
    "neuralNet    = MLPClassifier()\n",
    "neuralNet_reg= MLPRegressor(solver=\"lbfgs\")\n",
    "neighbors    = KNeighborsClassifier(weights = \"distance\", n_neighbors=9)\n",
    "xgb          = xgboost.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)\n",
    "\n",
    "models = {\"tree\"         :tree,\n",
    "          \"logistic\"     :logistic,\n",
    "          \"linear\"       :linear,\n",
    "          \"randomForest\" :randomForest,\n",
    "          \"boostedTree\"  :boostedTree,\n",
    "          \"svm\"          :svm,\n",
    "          \"neuralNet\"    :neuralNet,\n",
    "          \"neighbors\"    :neighbors,\n",
    "          \"XGBoost\"      :xgb\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree has been trained successfully\n",
      "logistic has been trained successfully\n",
      "randomForest has been trained successfully\n",
      "boostedTree has been trained successfully\n",
      "neuralNet has been trained successfully\n",
      "neighbors has been trained successfully\n",
      "XGBoost has been trained successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>logistic</th>\n",
       "      <th>randomForest</th>\n",
       "      <th>boostedTree</th>\n",
       "      <th>neuralNet</th>\n",
       "      <th>neighbors</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.677901</td>\n",
       "      <td>0.660424</td>\n",
       "      <td>0.814016</td>\n",
       "      <td>0.803042</td>\n",
       "      <td>0.652154</td>\n",
       "      <td>0.707187</td>\n",
       "      <td>0.778948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.452522</td>\n",
       "      <td>0.600405</td>\n",
       "      <td>0.945672</td>\n",
       "      <td>0.989570</td>\n",
       "      <td>0.992061</td>\n",
       "      <td>0.993618</td>\n",
       "      <td>0.992061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tree  logistic  randomForest  boostedTree  neuralNet  neighbors  \\\n",
       "AUC       0.677901  0.660424      0.814016     0.803042   0.652154   0.707187   \n",
       "Accuracy  0.452522  0.600405      0.945672     0.989570   0.992061   0.993618   \n",
       "\n",
       "           XGBoost  \n",
       "AUC       0.778948  \n",
       "Accuracy  0.992061  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Models binary\n",
    "\n",
    "models = {\"tree\"         :tree,\n",
    "          \"logistic\"     :logistic,\n",
    "          \"randomForest\" :randomForest,\n",
    "          \"boostedTree\"  :boostedTree,\n",
    "          #\"svm\"          :svm,\n",
    "          \"neuralNet\"    :neuralNet,\n",
    "          \"neighbors\"    :neighbors,\n",
    "          \"XGBoost\"      :xgb\n",
    "         }\n",
    "\n",
    "#Training models on training set\n",
    "for model in models:\n",
    "    models[model].fit(trainingSet[features],trainingSet[target])\n",
    "    print(f\"{model} has been trained successfully\")\n",
    "\n",
    "#Compute Accuracy and AUC for each model\n",
    "performances = {}\n",
    "\n",
    "for model in models:\n",
    "    predictions   = models[model].predict(validationSet[features])\n",
    "    probabilities = pd.DataFrame(models[model].predict_proba(validationSet[features]))[1]\n",
    "    accuracy      = accuracy_score(validationSet[target],predictions)\n",
    "    auc           = roc_auc_score(np.array(validationSet[target]),np.array(probabilities))\n",
    "    \n",
    "    performances[model] = {\"Accuracy\":accuracy,\"AUC\":auc}\n",
    "\n",
    "pd.DataFrame(performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree ['max_gift', 'last_gift', 'prov_East Flanders', 'gender_SoHo', 'prov_Brussels', 'gender_Female'] 74.06 %\n",
      "logistic ['max_gift', 'prov_East Flanders', 'gender_SoHo', 'prov_Hainut', 'prov_Brussels', 'prov_Namur', 'last_gift', 'prov_Walloon Brabant', 'language', 'n_gifts', 'gender_Female', 'prov_Luxembourg', 'dormant_flag'] 72.34 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-24fa60c5d802>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mpredictions\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidationSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_feat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[1;31m#probabilities = pd.DataFrame(models[model].predict_proba(testSet[new_feat]))[1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[0mprobabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidationSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_feat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m                 \u001b[1;31m#accuracy      = accuracy_score(testSet[target],predictions)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0maccuracy\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidationSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m             delayed(_accumulate_prediction)(e.predict_proba, X, all_proba,\n\u001b[0;32m    600\u001b[0m                                             lock)\n\u001b[1;32m--> 601\u001b[1;33m             for e in self.estimators_)\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mproba\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m     \"\"\"\n\u001b[1;32m--> 394\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    852\u001b[0m             \u001b[0mnormalizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m             \u001b[0mnormalizer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnormalizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m             \u001b[0mproba\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Stepwise Feature Selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "models = {\"tree\"         :tree,\n",
    "          \"logistic\"     :logistic,\n",
    "          \"randomForest\" :randomForest,\n",
    "          \"boostedTree\"  :boostedTree,\n",
    "          #\"svm\"          :svm,\n",
    "          #\"neuralNet\"    :neuralNet,\n",
    "          \"neighbors\"    :neighbors\n",
    "          #\"XGBoost\"      :xgb\n",
    "         }\n",
    "\n",
    "predictors = features\n",
    "score_list = []\n",
    "performances = {}\n",
    "\n",
    "for model in models:\n",
    "    score_list = []\n",
    "    winners = []\n",
    "    \n",
    "    for index, var in enumerate(predictors):\n",
    "        new_feat = []\n",
    "        for i in range(len(predictors)):\n",
    "            if predictors[i] not in winners:\n",
    "                new_feat = winners.copy()\n",
    "                new_feat.append(predictors[i])\n",
    "                models[model].fit(trainingSet[new_feat], trainingSet[target])\n",
    "                #predictions   = models[model].predict(testSet[new_feat])\n",
    "                predictions   = models[model].predict(validationSet[new_feat])\n",
    "                #probabilities = pd.DataFrame(models[model].predict_proba(testSet[new_feat]))[1]\n",
    "                probabilities = pd.DataFrame(models[model].predict_proba(validationSet[new_feat]))[1]\n",
    "                #accuracy      = accuracy_score(testSet[target],predictions)\n",
    "                accuracy      = accuracy_score(validationSet[target],predictions)\n",
    "                #auc           = roc_auc_score(np.array(testSet[target]),np.array(probabilities))\n",
    "                auc           = roc_auc_score(np.array(validationSet[target]),np.array(probabilities))\n",
    "                \n",
    "\n",
    "                score_list.append([predictors[i], auc])\n",
    "                if len(score_list) > 1:\n",
    "                    if score_list[1][1] > score_list[0][1]:\n",
    "                        del(score_list[0])\n",
    "                    else:\n",
    "                        del(score_list[1])\n",
    "                        \n",
    "        if score_list[0][0] not in winners:\n",
    "            winners.append(score_list[0][0])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    acc = int(score_list[0][1] * 10000)/10000\n",
    "    print(model, winners, str(round(acc*100,2)) + \" %\" )\n",
    "    performances[model] = {\"Features\":winners, \"AUC\":acc}\n",
    "    \n",
    "pd.DataFrame(performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisherscore(X, y):\n",
    "    \n",
    "    # Get the list of independent variables\n",
    "    vars_list = X.columns\n",
    "    \n",
    "    # Get the unique values of dependent/target variable\n",
    "    # Should be 2 classes [0, 1]\n",
    "    target_unique = y.unique()\n",
    "  \n",
    "    iv_fisherscore = []\n",
    "    \n",
    "    for v in vars_list:\n",
    "        fs = np.abs(np.mean(X.loc[y == target_unique[0], v]) - \\\n",
    "                    np.mean(X.loc[y == target_unique[1], v])) / \\\n",
    "             np.sqrt(np.var(X.loc[y == target_unique[0], v]) + \\\n",
    "                     np.var(X.loc[y == target_unique[1], v]))\n",
    "        iv_fisherscore.append(fs)\n",
    "        \n",
    "    return pd.DataFrame(iv_fisherscore, index=vars_list, columns=['fisher_score'])\n",
    "\n",
    "res = fisherscore(trainingSet, trainingSet[target])\n",
    "res1 = res.sort_values(\"fisher_score\", ascending=False)[2:12]\n",
    "list(res1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "\n",
    "models = {\"tree\"         :tree,\n",
    "          \"logistic\"     :logistic,\n",
    "          \"randomForest\" :randomForest,\n",
    "          \"boostedTree\"  :boostedTree,\n",
    "          #\"svm\"          :svm,\n",
    "          #\"neuralNet\"    :neuralNet,\n",
    "          \"neighbors\"    :neighbors\n",
    "          #\"XGBoost\"      :xgb\n",
    "         }\n",
    "\n",
    "final_features = pd.DataFrame(performances).iloc[1,:]\n",
    "final_features[3] = list(res1.index)\n",
    "performances2 = {}\n",
    "performances_test = {}\n",
    "\n",
    "for i in range(0,len(final_features)):\n",
    "    model = final_features.index[i]\n",
    "    models[model].fit(trainingSet[final_features[i]], trainingSet[target])\n",
    "    predictions   = models[model].predict(testSet[final_features[i]])\n",
    "    probabilities = pd.DataFrame(models[model].predict_proba(testSet[final_features[i]]))[1]\n",
    "    accuracy      = accuracy_score(testSet[target],predictions)\n",
    "    auc           = roc_auc_score(np.array(testSet[target]),np.array(probabilities))\n",
    "    performances_test[model] = predictions\n",
    "\n",
    "    performances2[model] = {\"Accuracy\":accuracy,\"AUC\":auc}\n",
    "    print(model, auc, \"\\n\", confusion_matrix(testSet[target], predictions), \"\\n\",\n",
    "          confusion_matrix(testSet[target], predictions)[1][1]/(confusion_matrix(testSet[target], predictions)[1][1] + confusion_matrix(testSet[target], predictions)[0][1]))\n",
    "    score = cross_val_score(models[model], trainingSet[final_features[i]], trainingSet[target], cv=5, scoring='roc_auc') \n",
    "    print(\"cv score:\",str(round(score.mean(),4)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of 1's predicted\n",
    "\n",
    "test = pd.DataFrame(performances)\n",
    "test[\"actual\"] = [\"0\"] * len(test)\n",
    "test[\"donorID\"] = [\"0\"] * len(test)\n",
    "test.actual = testSet[target]\n",
    "test.donorID = dsc_copy[\"donorID\"]\n",
    "#test[test[0]==1]\n",
    "for x in test.columns:\n",
    "    print(x, test[x][test[x] == 1].sum())\n",
    "print(testSet[target].sum()/len(testSet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Profile of 1's\n",
    "\n",
    "chosen_model = \"randomForest\"\n",
    "\n",
    "\n",
    "test_1 = test[test.actual == 1]\n",
    "print(test_1.shape)\n",
    "\n",
    "mod_feat = final_features[chosen_model]\n",
    "mod_feat.append(\"donorID\")\n",
    "mod_feat.append(\"y\")\n",
    "mod_feat.append(\"mean_gift\")\n",
    "df_mod_feat = dsc_copy.loc[:, mod_feat]\n",
    "\n",
    "left_table = test_1\n",
    "right_table = df_mod_feat\n",
    "\n",
    "profile = pd.merge(left_table, right_table, \n",
    "         how=\"left\", \n",
    "         left_on=\"donorID\", \n",
    "         right_on=\"donorID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = profile[profile[chosen_model] == 1].describe()\n",
    "prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"max_depth\": list(range(2,6)),\n",
    "              \"max_features\": list(range(1,7)),\n",
    "              \"min_samples_leaf\": list(range(1,7)),\n",
    "              \"criterion\": ['entropy','gini']}\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist,n_iter =10, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(trainingSet[final_features[0]], trainingSet[target])\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))\n",
    "print(tree_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tree_cv.best_estimator_.fit(trainingSet[final_features[0]],trainingSet[target])\n",
    "predictions   = tree_cv.best_estimator_.predict(testSet[final_features[0]])\n",
    "print(confusion_matrix(testSet[target], predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_dist = {\"penalty\": [\"l1\", \"l2\"]}\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "log = LogisticRegression()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "log_cv = RandomizedSearchCV(log, param_dist,n_iter =10, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "log_cv.fit(trainingSet[final_features[1]], trainingSet[target])\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(log_cv.best_params_))\n",
    "print(\"Best score is {}\".format(log_cv.best_score_))\n",
    "print(log_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "log_cv.best_estimator_.fit(trainingSet[final_features[1]],trainingSet[target])\n",
    "predictions   = log_cv.best_estimator_.predict(testSet[final_features[1]])\n",
    "print(confusion_matrix(testSet[target], predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "perf_df = pd.DataFrame(performances)\n",
    "for model in perf_df:\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    sns.heatmap(dsc[perf_df[model][\"Features\"]].corr(),square=True,cmap='RdYlGn',ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ieseg import partition\n",
    "from ieseg import roc\n",
    "from ieseg import lift\n",
    "from ieseg import cumulativeResponse\n",
    "from ieseg import cumulativeGains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances = pd.DataFrame(performances)\n",
    "\n",
    "lifts     = {}\n",
    "responses = {}\n",
    "gains     = {}\n",
    "data      = pd.DataFrame(testSet[target]).copy()\n",
    "\n",
    "for (index,model) in enumerate(models):\n",
    "    feature = performances.loc[\"Features\", model]\n",
    "    models[model].fit(trainingSet[feature], trainingSet[target])\n",
    "    data[f\"proba {model}\"] = pd.DataFrame(models[model].predict_proba(testSet[feature]))[1]\n",
    "    lifts[model] = lift(dataSet = data, actuals = target, probability = \"proba \"+str(model))\n",
    "    responses[model] = cumulativeResponse(dataSet = data, actuals = target, probability = \"proba \"+str(model))\n",
    "    gains[model] = cumulativeGains(dataSet = data, actuals = target, probability = \"proba \"+str(model))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    pyplot.plot(lifts[model][\"Quantile\"], lifts[model][\"Lift\"])\n",
    "    pyplot.gca().invert_xaxis()\n",
    "    pyplot.xlabel(\"Quantile\")\n",
    "    pyplot.ylabel(\"lift\")\n",
    "    pyplot.title(\"Lift\")\n",
    "    pyplot.legend(lifts)\n",
    "    pyplot.rcParams[\"figure.figsize\"] = (20,10)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    pyplot.plot(responses[model][\"Quantile\"], responses[model][\"Cumulative response\"])\n",
    "    pyplot.gca().invert_xaxis()\n",
    "    pyplot.xlabel(\"Quantile\")\n",
    "    pyplot.ylabel(\"Response\")\n",
    "    pyplot.title(\"Cumulative Response\")\n",
    "    pyplot.legend(responses)\n",
    "    pyplot.rcParams[\"figure.figsize\"] = (20,10)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    pyplot.plot(gains[model][\"Quantile\"], gains[model][\"Cumulative gains\"])\n",
    "    pyplot.gca().invert_xaxis()\n",
    "    pyplot.xlabel(\"Quantile\")\n",
    "    pyplot.ylabel(\"Gains\")\n",
    "    pyplot.title(\"Cumulative Gains\")\n",
    "    pyplot.legend(gains)\n",
    "    pyplot.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifts[model].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gains[model].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses[model].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Continous (work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet[features].head()\n",
    "\n",
    "# trainingSet[features] = trainingSet2\n",
    "# testSet[features] = testSet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continous PCA\n",
    "#testSet[target].hist(bins=100) \n",
    "#skewed: max_gift,min_gift,mean_gift,n_gifts,avg_datediff\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics       import mean_squared_error\n",
    "\n",
    "testSet[target] = np.log(testSet[target] + 1)\n",
    "trainingSet[target] = np.log(trainingSet[target] + 1)\n",
    "\n",
    "def normalize(column):\n",
    "    upper = column.max()\n",
    "    lower = column.min()\n",
    "    y = (column - lower)/(upper-lower)\n",
    "    return y\n",
    "\n",
    "models = {\"neuralNet_reg\":neuralNet_reg,\n",
    "          \"linear\"       :linear,\n",
    "          \"XGBoost\"      :xgb,\n",
    "          \"Lasso\"        :lasso\n",
    "         }\n",
    "\n",
    "nofeature = [\"y\", \"amount\"]\n",
    "features = list(set(dsc.columns).difference(set(nofeature)))\n",
    "target= 'amount'\n",
    "skew = ['max_gift','min_gift','mean_gift','n_gifts','avg_datediff']\n",
    "\n",
    "for i in trainingSet[features]:\n",
    "    if i in skew:\n",
    "        trainingSet[i] = normalize(np.log(trainingSet[i]+1))\n",
    "        testSet[i] = normalize(np.log(testSet[i]+1))\n",
    "\n",
    "\n",
    "#pca = PCA()\n",
    "#pca_train = pca.fit_transform(trainingSet[features].values)\n",
    "#pca_test = pca.transform(testSet[features].values)\n",
    "\n",
    "# exp_var_pca = pca.explained_variance_ratio_\n",
    "\n",
    "# pca_train = pca_train\n",
    "# pca_test = pca_test\n",
    "\n",
    "skipped=[]\n",
    "performances = {}\n",
    "\n",
    "for model in models:\n",
    "    #models[model].fit(pca_train, trainingSet[target])\n",
    "    models[model].fit(trainingSet[features], trainingSet[target])\n",
    "    print(f\"{model} has been trained successfully\")\n",
    "for model in models:\n",
    "    if model not in skipped:\n",
    "        #predictions      = models[model].predict(pca_test)\n",
    "        predictions      = models[model].predict(testSet[features])\n",
    "        RMSE             = np.sqrt(mean_squared_error(testSet[target],predictions))\n",
    "        mean_train       = np.mean(testSet[target])\n",
    "        score            = RMSE / (testSet[target].max() - testSet[target].min())\n",
    "        print(model, score)\n",
    "        performances[model] = predictions\n",
    "pd.DataFrame(performances).head()\n",
    "perform = pd.DataFrame(performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform[\"actual\"] = [\"0\"] * len(perform)\n",
    "perform.actual = np.exp(testSet[target]) - 1\n",
    "\n",
    "for mod in range(len(perform.columns)-1):\n",
    "    x = perform[\"actual\"] - perform.iloc[:, mod]\n",
    "    print(perform.columns[mod], \"\\t\", x.mean())\n",
    "perform[perform.actual != 0].head(50)\n",
    "#perform.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [\"neuralNet_reg\",\"linear\",\"XGBoost\",\"Ridge\"]:\n",
    "    fig, ax = plt.subplots(figsize=(2,2))\n",
    "    plt.scatter(perform[i],perform['actual'])\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testSet['amount'].hist(bins=100) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
